{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd48b153",
   "metadata": {},
   "source": [
    "Importing required libraries and passing google credentials json as a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5f2f999e-6004-4742-90d3-0a490533229b",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import col,isnan,when,year,month\n",
    "credentials_location = '/home/amanhd9/.google/credentials/google_credentials.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407cc18c",
   "metadata": {},
   "source": [
    "Configuring the spark session to connect with GCS and Google BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9fc50795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conf = SparkConf() \\\n",
    "    .setMaster('local[*]') \\\n",
    "    .setAppName('test') \\\n",
    "    .set(\"spark.jars\", \"/home/amanhd9/SPARK/spark-3.3.3-bin-hadoop3/jars/gcs-connector-hadoop3-latest.jar\") \\\n",
    "    .set(\"spark.jars\", \"/home/amanhd9/SPARK/spark-3.3.3-bin-hadoop3/jars/spark-3.3-bigquery-0.32.2.jar\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.enable\", \"true\") \\\n",
    "    .set(\"spark.hadoop.google.cloud.auth.service.account.json.keyfile\", credentials_location)\n",
    "    \n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "hadoop_conf = sc._jsc.hadoopConfiguration()\n",
    "\n",
    "hadoop_conf.set(\"fs.AbstractFileSystem.gs.impl\",  \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "hadoop_conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.json.keyfile\", credentials_location)\n",
    "hadoop_conf.set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(conf=sc.getConf()) \\\n",
    "    .getOrCreate()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd70b0",
   "metadata": {},
   "source": [
    "Reading from Google Big Query Warehouse staging schema using spark.read method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc7903",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_table_name = \"data-eng-399920.stg.sales-data\"\n",
    "stores_table_name = \"data-eng-399920.stg.stores-data\" \n",
    "\n",
    "df_sales = spark.read \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"table\", sales_table_name) \\\n",
    "    .load()\n",
    "    \n",
    "df_stores= spark.read \\\n",
    "    .format(\"bigquery\") \\\n",
    "    .option(\"table\", stores_table_name) \\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c78519e",
   "metadata": {},
   "source": [
    "Checking count of the sales data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "07990ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19454838"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8f6632d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\n",
      "|product_id|store_id|               date|sales|revenue|stock|price|promo_type_1|promo_bin_1|promo_type_2|promo_bin_2|promo_discount_2|promo_discount_type_2|\n",
      "+----------+--------+-------------------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\n",
      "|     P0512|   S0072|2019-10-25 00:00:00|  0.0|    0.0|  4.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0073|2019-10-25 00:00:00|  0.0|    0.0|  3.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0074|2019-10-25 00:00:00|  0.0|    0.0| 11.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0075|2019-10-25 00:00:00|  0.0|    0.0|  6.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0076|2019-10-25 00:00:00|  0.0|    0.0|  2.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0077|2019-10-25 00:00:00|  0.0|    0.0|  1.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0078|2019-10-25 00:00:00|  0.0|    0.0|  3.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0079|2019-10-25 00:00:00|  0.0|    0.0|  5.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0080|2019-10-25 00:00:00|  0.0|    0.0|  4.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0081|2019-10-25 00:00:00|  0.0|    0.0|  9.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0082|2019-10-25 00:00:00|  0.0|    0.0|  3.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0083|2019-10-25 00:00:00|  0.0|    0.0|  4.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0084|2019-10-25 00:00:00|  0.0|    0.0|  7.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0085|2019-10-25 00:00:00|  0.0|    0.0| 33.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0086|2019-10-25 00:00:00|  0.0|    0.0|  2.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0087|2019-10-25 00:00:00|  0.0|    0.0|  4.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0088|2019-10-25 00:00:00|  0.0|    0.0|  7.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0089|2019-10-25 00:00:00|  0.0|    0.0|  3.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0091|2019-10-25 00:00:00|  0.0|    0.0|  2.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "|     P0512|   S0092|2019-10-25 00:00:00|  0.0|    0.0|  4.0| 19.9|        PR10|       high|        PR03|       null|            null|                 null|\n",
      "+----------+--------+-------------------+-----+-------+-----+-----+------------+-----------+------------+-----------+----------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0f0de1",
   "metadata": {},
   "source": [
    "Having a look at the data frame structure shows columns which are not relavent for sales and revenue insights, thus dropping them.\n",
    "Also a lot of rows have sales as 0, which is incorrect thus dropping such rows as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3cdf08a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------------------+-----+-------+-----+\n",
      "|product_id|store_id|               date|sales|revenue|price|\n",
      "+----------+--------+-------------------+-----+-------+-----+\n",
      "|     P0017|   S0025|2017-01-02 00:00:00|  1.0|   1.38| 1.49|\n",
      "|     P0015|   S0082|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "|     P0017|   S0020|2017-01-02 00:00:00|  3.0|   4.14| 1.49|\n",
      "|     P0015|   S0001|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "|     P0015|   S0068|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "|     P0016|   S0032|2017-01-02 00:00:00|  1.0|   1.85|  2.0|\n",
      "|     P0017|   S0015|2017-01-02 00:00:00|  2.0|   2.76| 1.49|\n",
      "|     P0001|   S0056|2017-01-02 00:00:00|  1.0|    5.3| 6.25|\n",
      "|     P0004|   S0044|2017-01-02 00:00:00|  1.0|   3.81|  4.5|\n",
      "|     P0015|   S0032|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "|     P0015|   S0040|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "|     P0015|   S0085|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "|     P0015|   S0130|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "|     P0017|   S0008|2017-01-02 00:00:00|  1.0|   1.38| 1.49|\n",
      "|     P0017|   S0012|2017-01-02 00:00:00|  1.0|   1.38| 1.49|\n",
      "|     P0001|   S0012|2017-01-02 00:00:00|  1.0|    5.3| 6.25|\n",
      "|     P0001|   S0013|2017-01-02 00:00:00|  2.0|  10.59| 6.25|\n",
      "|     P0001|   S0103|2017-01-02 00:00:00|  1.0|    5.3| 6.25|\n",
      "|     P0001|   S0106|2017-01-02 00:00:00|  1.0|    5.3| 6.25|\n",
      "|     P0015|   S0002|2017-01-02 00:00:00|  1.0|   2.41|  2.6|\n",
      "+----------+--------+-------------------+-----+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3189682"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales=df_sales.drop('stock','promo_type_1','promo_bin_1','promo_type_2', \\\n",
    "'promo_bin_2','promo_discount_2','promo_discount_type_2')\n",
    "df_sales=df_sales.orderBy('date').filter('sales != 0.0')\n",
    "df_sales.show()\n",
    "df_sales.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c30909a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+-------+\n",
      "|store_id|storetype_id|store_size|city_id|\n",
      "+--------+------------+----------+-------+\n",
      "|   S0091|        ST04|        19|   C013|\n",
      "|   S0012|        ST04|        28|   C005|\n",
      "|   S0045|        ST04|        17|   C008|\n",
      "|   S0032|        ST03|        14|   C019|\n",
      "|   S0027|        ST04|        24|   C022|\n",
      "|   S0088|        ST04|        20|   C009|\n",
      "|   S0095|        ST02|        44|   C014|\n",
      "|   S0055|        ST04|        24|   C014|\n",
      "|   S0099|        ST03|        14|   C014|\n",
      "|   S0078|        ST04|        19|   C036|\n",
      "|   S0006|        ST03|         8|   C024|\n",
      "|   S0135|        ST03|        16|   C035|\n",
      "|   S0066|        ST04|        47|   C033|\n",
      "|   S0106|        ST04|        21|   C031|\n",
      "|   S0112|        ST04|        46|   C031|\n",
      "|   S0059|        ST03|        15|   C014|\n",
      "|   S0129|        ST04|        18|   C021|\n",
      "|   S0116|        ST03|        15|   C031|\n",
      "|   S0098|        ST03|        15|   C022|\n",
      "|   S0049|        ST04|        25|   C031|\n",
      "+--------+------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stores.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2340122",
   "metadata": {},
   "source": [
    "Having a look at stores data frame shows that joining it with the sales data frame can give us better representation of which store or city is fetching better revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1d6d8c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------------+-----+-------+-----+------------+----------+-------+\n",
      "|store_id|product_id|               date|sales|revenue|price|storetype_id|store_size|city_id|\n",
      "+--------+----------+-------------------+-----+-------+-----+------------+----------+-------+\n",
      "|   S0001|     P0499|2017-01-02 00:00:00|  1.0|   0.69| 0.75|        ST04|        41|   C031|\n",
      "|   S0001|     P0311|2017-01-02 00:00:00|  3.0|    3.0|  1.0|        ST04|        41|   C031|\n",
      "|   S0001|     P0439|2017-01-02 00:00:00|  3.0|  20.97| 8.25|        ST04|        41|   C031|\n",
      "|   S0001|     P0148|2017-01-02 00:00:00|  4.0|   21.3| 5.75|        ST04|        41|   C031|\n",
      "|   S0001|     P0287|2017-01-02 00:00:00|  1.0|   5.56|  7.5|        ST04|        41|   C031|\n",
      "|   S0001|     P0348|2017-01-02 00:00:00|  2.0|   3.11|  2.1|        ST04|        41|   C031|\n",
      "|   S0001|     P0438|2017-01-02 00:00:00|  9.0|   2.08| 0.25|        ST04|        41|   C031|\n",
      "|   S0001|     P0035|2017-01-02 00:00:00|  2.0|   4.54| 2.45|        ST04|        41|   C031|\n",
      "|   S0001|     P0140|2017-01-02 00:00:00|  2.0|   11.0|  5.5|        ST04|        41|   C031|\n",
      "|   S0001|     P0185|2017-01-02 00:00:00|  2.0|    1.5| 0.75|        ST04|        41|   C031|\n",
      "|   S0001|     P0219|2017-01-02 00:00:00|  1.0|   6.71| 7.25|        ST04|        41|   C031|\n",
      "|   S0001|     P0327|2017-01-02 00:00:00|  1.0|   1.81| 1.95|        ST04|        41|   C031|\n",
      "|   S0001|     P0333|2017-01-02 00:00:00|  3.0|   5.14| 1.85|        ST04|        41|   C031|\n",
      "|   S0001|     P0413|2017-01-02 00:00:00|1.695|   3.12| 1.99|        ST04|        41|   C031|\n",
      "|   S0001|     P0436|2017-01-02 00:00:00|  1.0|   2.78|  3.0|        ST04|        41|   C031|\n",
      "|   S0001|     P0015|2017-01-02 00:00:00|  1.0|   2.41|  2.6|        ST04|        41|   C031|\n",
      "|   S0001|     P0663|2017-01-02 00:00:00|  7.0|  21.06| 3.25|        ST04|        41|   C031|\n",
      "|   S0001|     P0103|2017-01-02 00:00:00| 13.0|   31.9| 2.65|        ST04|        41|   C031|\n",
      "|   S0001|     P0110|2017-01-02 00:00:00|  1.0|   2.73| 2.95|        ST04|        41|   C031|\n",
      "|   S0001|     P0169|2017-01-02 00:00:00|  1.0|   4.23| 4.99|        ST04|        41|   C031|\n",
      "+--------+----------+-------------------+-----+-------+-----+------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = df_sales.join(df_stores,on='store_id',how='outer').orderBy('date','store_id')\n",
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cb1d1",
   "metadata": {},
   "source": [
    "checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "385e31d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'store_id': 0,\n",
       " 'product_id': 0,\n",
       " 'date': 0,\n",
       " 'sales': 0,\n",
       " 'revenue': 0,\n",
       " 'price': 145892,\n",
       " 'storetype_id': 0,\n",
       " 'store_size': 0,\n",
       " 'city_id': 0}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_Null = {col:df_join.filter(df_join[col].isNull()).count() for col in df_join.columns}\n",
    "Dict_Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8217b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 108:======================>                                  (2 + 3) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-------------------+-----+-------+-----+------------+----------+-------+\n",
      "|store_id|product_id|               date|sales|revenue|price|storetype_id|store_size|city_id|\n",
      "+--------+----------+-------------------+-----+-------+-----+------------+----------+-------+\n",
      "|   S0028|     P0348|2017-01-02 00:00:00|  3.0|   4.58| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0177|2017-01-02 00:00:00|  4.0|   6.78| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0333|2017-01-02 00:00:00|  8.0|  14.81| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0079|2017-01-02 00:00:00|  1.0|   2.08| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0131|2017-01-02 00:00:00|  4.0|   8.33| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0226|2017-01-02 00:00:00|  3.0|   4.17| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0327|2017-01-02 00:00:00|  1.0|   2.64| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0018|2017-01-02 00:00:00|  2.0|   3.61| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0060|2017-01-02 00:00:00|  1.0|  13.47| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0125|2017-01-02 00:00:00|  2.0|   5.83| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0129|2017-01-02 00:00:00|  8.0|   73.9| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0196|2017-01-02 00:00:00|  2.0|   9.26| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0211|2017-01-02 00:00:00|  1.0|   7.62| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0261|2017-01-02 00:00:00|  4.0|  19.44| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0275|2017-01-02 00:00:00|  1.0|   2.08| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0017|2017-01-02 00:00:00|  5.0|   4.63| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0390|2017-01-02 00:00:00|  1.0|   8.35| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0035|2017-01-02 00:00:00|  1.0|   3.84| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0051|2017-01-02 00:00:00|  4.0|   2.59| null|        ST01|        86|   C036|\n",
      "|   S0028|     P0103|2017-01-02 00:00:00| 14.0|  36.16| null|        ST01|        86|   C036|\n",
      "+--------+----------+-------------------+-----+-------+-----+------------+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.filter(col('price').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dd1538",
   "metadata": {},
   "source": [
    "Found multiple null values in price column, but that will not put impact on our revenue and sales value as there are separate columns already present for these values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e295e575",
   "metadata": {},
   "source": [
    "The resulting data frame is written to the Production schema as the revenue-data table,but for easy visualization and comparison between monthly data , Splitting the data frame into monthly data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e85dfa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join_with_year_month = df_join.withColumn(\"year\", year(\"date\")).withColumn(\"month\", month(\"date\"))\n",
    "unique_year_month = df_join_with_year_month.select(\"year\", \"month\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7ad8d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_month_data_frames = {}\n",
    "\n",
    "for row in unique_year_month:\n",
    "    year = row.year\n",
    "    month = row.month\n",
    "    year_month_data_frames[(year, month)] = \\\n",
    "    df_join_with_year_month.filter((df_join_with_year_month.year == year) \\\n",
    "    & (df_join_with_year_month.month == month))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c878f56",
   "metadata": {},
   "source": [
    "year_month_data_frames dictionary will contain data frames of each month, these will come useful when comparing monthly revenue data using Looker studio, the data frames have been written to big query tables using ./Spark/transform_upload.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "924d714a-3339-4526-bc9a-4dc534d7eee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
